{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "En este documento estamos tomando un dataset que se nos dio por medio de canvas con la informacion de diferentes cliente de una aseguradora, en la que se tiene informacion personal de los clientes asi como el costo del seguro, con esto el objetivo sera crear un modelo que nos permita predecir el costo del seguro de un cliente nuevo.\n",
    "\n",
    "En base a lo que hemos aprendido decidi que para esta entrega realizare una red neuronal, simplemente por el hecho de que es un modelo que no hemos tenido la oportunidad de practir como otros modelos de machine learning, por lo que me parecio una buena oportunidad para aprender a usarlo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "191dd8651feda9b7"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:00.246319700Z",
     "start_time": "2023-08-30T23:38:00.229308100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importamos el dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f22d3ac0f3ffd619"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'E:\\Github\\Portafolio_Implementacion\\ConFrameworks\\insurance.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:01.037970300Z",
     "start_time": "2023-08-30T23:38:01.026960900Z"
    }
   },
   "id": "36af4f6a071b8fab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "checamos las columnas del dataset, podemos ver que no hay valores nulos y que hay 3 varaibles categoricas que necesitaremos cambiar para poder crear nuestros modelos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee49b6ef2e160762"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:01.462921300Z",
     "start_time": "2023-08-30T23:38:01.428372800Z"
    }
   },
   "id": "1666d070635ad2d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cambiamos las variables categoricas a numericas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43b9ce16c7f6827b"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "df['smoker'] = df['smoker'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "df = pd.get_dummies(df, columns=['region'], drop_first=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:01.797219500Z",
     "start_time": "2023-08-30T23:38:01.776201500Z"
    }
   },
   "id": "57019fcb10a7a9dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "creamos los conjuntos de input y output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15c19124562a74c3"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['charges'])\n",
    "y = df['charges']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:02.432154500Z",
     "start_time": "2023-08-30T23:38:02.415139200Z"
    }
   },
   "id": "2c8fa5b13f29fcc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "creamos los conjuntos de entrenamiento y prueba"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e58acd727b09ac4"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:03.064497700Z",
     "start_time": "2023-08-30T23:38:03.046647400Z"
    }
   },
   "id": "4e7d2873086a56d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "escalamos los datos, esto es necesario para que la red neuronal pueda trabajar con ellos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c3730ee795676a9"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:03.645309600Z",
     "start_time": "2023-08-30T23:38:03.637302500Z"
    }
   },
   "id": "6c51db66dbb3a8fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "creamos los tensores de pytorch, estos son los datos que usaremos para entrenar y probar el modelo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9353ce125585019"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:04.356148100Z",
     "start_time": "2023-08-30T23:38:04.343136Z"
    }
   },
   "id": "32800f468de08342"
  },
  {
   "cell_type": "markdown",
   "source": [
    "creamos la red neuronal, en este caso es una red neuronal simple con 3 capas, la primera capa tiene 32 neuronas, la segunda 16 y la ultima 1, la funcion de activacion es relu para las primeras 2 capas y no hay funcion de activacion para la ultima capa ya que es una regresion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f92de5217347503"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "class SimpleInsuranceNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleInsuranceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = SimpleInsuranceNN(X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:05.141311300Z",
     "start_time": "2023-08-30T23:38:05.121300Z"
    }
   },
   "id": "36fcd959f6da0344"
  },
  {
   "cell_type": "markdown",
   "source": [
    "entrenamos el modelo, en este caso lo entrenamos por 1000 epocas, cada 10 epocas imprimimos el loss para ver como va mejorando el modelo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd345318997db25"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 322382432.0\n",
      "Epoch [20/100], Loss: 322117152.0\n",
      "Epoch [30/100], Loss: 321397504.0\n",
      "Epoch [40/100], Loss: 319802176.0\n",
      "Epoch [50/100], Loss: 316749376.0\n",
      "Epoch [60/100], Loss: 311529024.0\n",
      "Epoch [70/100], Loss: 303333792.0\n",
      "Epoch [80/100], Loss: 291276544.0\n",
      "Epoch [90/100], Loss: 274524064.0\n",
      "Epoch [100/100], Loss: 252680112.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.1f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:05.918359700Z",
     "start_time": "2023-08-30T23:38:05.808260900Z"
    }
   },
   "id": "949be3cb67669b91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "evaluamos el modelo con los datos de prueba, podemos ver que la perdida es muy alta por lo que el modelo no es muy bueno, hay que recordar que las redes neuronales no son muy buenas en datos tabulares, ademas de esto el dataset es muy peque√±o por lo que no hay muchos datos para entrenar el modelo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9006aa05de00426a"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 249277632.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.1f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:07.920671900Z",
     "start_time": "2023-08-30T23:38:07.902656400Z"
    }
   },
   "id": "8b3feb80e2824aeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "para hacer un intento mas con redes neuronales modificaremos los datos para que la variable de salida sea un problema de clasificacion.\n",
    "\n",
    "para hacer esto lo que haremos es dividir el costo del seguro en 3 categorias, bajo, medio y alto, para esto usaremos los cuartiles de los datos, los datos que esten en el primer cuartil seran bajo (0), los que esten en el segundo cuartil seran medio (1) y los que esten en el tercer cuartil seran alto (2)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5910b107e9744043"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "Q1 = df['charges'].quantile(0.25)\n",
    "Q3 = df['charges'].quantile(0.75)\n",
    "\n",
    "df['category'] = 1\n",
    "df.loc[df['charges'] < Q1, 'category'] = 0\n",
    "df.loc[df['charges'] > Q3, 'category'] = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:09.680027100Z",
     "start_time": "2023-08-30T23:38:09.664103600Z"
    }
   },
   "id": "90d5b46e4af6f854"
  },
  {
   "cell_type": "markdown",
   "source": [
    "hacemos los mismos procesos que antes, solo que ahora la variable de salida es la categoria."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d2a052c8654e912"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['charges', 'category'])\n",
    "y = df['category']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:11.522791200Z",
     "start_time": "2023-08-30T23:38:11.512782Z"
    }
   },
   "id": "788e764101c03808"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:11.831112900Z",
     "start_time": "2023-08-30T23:38:11.827108500Z"
    }
   },
   "id": "497dda0c7b04f852"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:12.181556500Z",
     "start_time": "2023-08-30T23:38:12.166542800Z"
    }
   },
   "id": "51ec3c43c45bf7a0"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).view(-1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).view(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:12.824699600Z",
     "start_time": "2023-08-30T23:38:12.814690500Z"
    }
   },
   "id": "fff0f606660a6723"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "model = ClassificationNN(X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:13.155559200Z",
     "start_time": "2023-08-30T23:38:13.140545700Z"
    }
   },
   "id": "4be8e97644bc46c2"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.9408\n",
      "Epoch [20/100], Loss: 0.7254\n",
      "Epoch [30/100], Loss: 0.6653\n",
      "Epoch [40/100], Loss: 0.6531\n",
      "Epoch [50/100], Loss: 0.6475\n",
      "Epoch [60/100], Loss: 0.6454\n",
      "Epoch [70/100], Loss: 0.6440\n",
      "Epoch [80/100], Loss: 0.6432\n",
      "Epoch [90/100], Loss: 0.6426\n",
      "Epoch [100/100], Loss: 0.6421\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:14.444286400Z",
     "start_time": "2023-08-30T23:38:14.309164100Z"
    }
   },
   "id": "4756b4bb8614c6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.93%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T23:38:16.024895Z",
     "start_time": "2023-08-30T23:38:16.004876600Z"
    }
   },
   "id": "930155e7cdb518c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "En esta ultima prueba podemos cer que el modelo tiene una precision buena ahora que solo estamos clasificando si el seguro estara en una de 3 categorias."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e230aa0a772c37ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
