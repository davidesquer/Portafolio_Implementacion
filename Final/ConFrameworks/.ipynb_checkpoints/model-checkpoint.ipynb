{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191dd8651feda9b7",
   "metadata": {},
   "source": [
    "En este documento estamos tomando un dataset que se nos dio por medio de canvas con la informacion de diferentes cliente de una aseguradora, en la que se tiene informacion personal de los clientes asi como el costo del seguro, con esto el objetivo sera crear un modelo que nos permita predecir el costo del seguro de un cliente nuevo.\n",
    "\n",
    "En base a lo que hemos aprendido decidi que para esta entrega realizare una red neuronal, simplemente por el hecho de que es un modelo que no hemos tenido la oportunidad de practir como otros modelos de machine learning, por lo que me parecio una buena oportunidad para aprender a usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:45.572481200Z",
     "start_time": "2023-09-10T20:24:45.563867400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d3ac0f3ffd619",
   "metadata": {},
   "source": [
    "Importamos el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2320dc95f5f95",
   "metadata": {},
   "source": [
    "Para este proyecto utilizaremos una base de datos de personas aseguradas, en la que se tiene informacion personal de los clientes asi como el costo del seguro, con esto el objetivo sera crear un modelo que nos permita predecir el costo del seguro de un cliente nuevo.\n",
    "este es el dataset Insurance que se puede encontrar en: https://experiencia21.tec.mx/courses/406127/files/149437937?module_item_id=24944904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36af4f6a071b8fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:45.998082700Z",
     "start_time": "2023-09-10T20:24:45.988073100Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'E:\\Github\\Portafolio_Implementacion\\Final\\ConFrameworks\\insurance.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49b6ef2e160762",
   "metadata": {},
   "source": [
    "checamos las columnas del dataset, podemos ver que no hay valores nulos y que hay 3 varaibles categoricas que necesitaremos cambiar para poder crear nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1666d070635ad2d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:46.297090500Z",
     "start_time": "2023-09-10T20:24:46.276073200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9ce16c7f6827b",
   "metadata": {},
   "source": [
    "Cambiamos las variables categoricas a numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57019fcb10a7a9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:46.578120600Z",
     "start_time": "2023-09-10T20:24:46.569111700Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "df['smoker'] = df['smoker'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "df = pd.get_dummies(df, columns=['region'], drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c19124562a74c3",
   "metadata": {},
   "source": [
    "creamos los conjuntos de input y output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c8fa5b13f29fcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:46.888094700Z",
     "start_time": "2023-09-10T20:24:46.872081100Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['charges'])\n",
    "y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58acd727b09ac4",
   "metadata": {},
   "source": [
    "creamos los conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e7d2873086a56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:47.185283400Z",
     "start_time": "2023-09-10T20:24:47.173272800Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3730ee795676a9",
   "metadata": {},
   "source": [
    "escalamos los datos, esto es necesario para que la red neuronal pueda trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c51db66dbb3a8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:47.482014600Z",
     "start_time": "2023-09-10T20:24:47.468002400Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9353ce125585019",
   "metadata": {},
   "source": [
    "creamos los tensores de pytorch, estos son los datos que usaremos para entrenar y probar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32800f468de08342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:47.784076Z",
     "start_time": "2023-09-10T20:24:47.775285300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92de5217347503",
   "metadata": {},
   "source": [
    "creamos la red neuronal, en este caso es una red neuronal simple con 3 capas, la primera capa tiene 32 neuronas, la segunda 16 y la ultima 1, la funcion de activacion es relu para las primeras 2 capas y no hay funcion de activacion para la ultima capa ya que es una regresion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de502b0ecaf0ffe",
   "metadata": {},
   "source": [
    "Nuestro problema a resolver en esta etapa es una regresion, que es predecir un valor numerico no discreto en base a ciertos datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36fcd959f6da0344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:48.255259300Z",
     "start_time": "2023-09-10T20:24:48.251255300Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleInsuranceNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleInsuranceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = SimpleInsuranceNN(X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd345318997db25",
   "metadata": {},
   "source": [
    "entrenamos el modelo, en este caso lo entrenamos por 1000 epocas, cada 10 epocas imprimimos el loss para ver como va mejorando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "949be3cb67669b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:48.666278200Z",
     "start_time": "2023-09-10T20:24:48.554176100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 322370816.0\n",
      "Epoch [20/100], Loss: 322090688.0\n",
      "Epoch [30/100], Loss: 321328544.0\n",
      "Epoch [40/100], Loss: 319632960.0\n",
      "Epoch [50/100], Loss: 316373088.0\n",
      "Epoch [60/100], Loss: 310778816.0\n",
      "Epoch [70/100], Loss: 302017696.0\n",
      "Epoch [80/100], Loss: 289305248.0\n",
      "Epoch [90/100], Loss: 272045472.0\n",
      "Epoch [100/100], Loss: 250019872.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006aa05de00426a",
   "metadata": {},
   "source": [
    "evaluamos el modelo con los datos de prueba, podemos ver que la perdida es muy alta por lo que el modelo no es muy bueno, hay que recordar que las redes neuronales no son muy buenas en datos tabulares, ademas de esto el dataset es muy peque√±o por lo que no hay muchos datos para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b3feb80e2824aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:48.893484500Z",
     "start_time": "2023-09-10T20:24:48.869462100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 245675632.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a99c2d6d637e",
   "metadata": {},
   "source": [
    "El test loss representa el error cuadrado promedio entre las predicciones y los valores reales podemos ver que este es muy alto, por lo que el modelo no es muy bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134643e3eb13e29",
   "metadata": {},
   "source": [
    "Aqui tenemos predicciones para 3 elementos del conjunto de prueba, podemos ver que las predicciones son muy diferentes a los valores reales, y que el modelo no es bueno para predecir el costo del seguro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9488e7cf841d81f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:49.365483300Z",
     "start_time": "2023-09-10T20:24:49.351470900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1442.8323],\n",
       "        [1333.4028],\n",
       "        [4724.2036]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(X_test_tensor[:3], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbdf97c2e68315c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:49.523432700Z",
     "start_time": "2023-09-10T20:24:49.515425900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9095.0684],\n",
       "        [ 5272.1758],\n",
       "        [29330.9824]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910b107e9744043",
   "metadata": {},
   "source": [
    "para hacer un intento mas con redes neuronales modificaremos los datos para que la variable de salida sea un problema de clasificacion.\n",
    "\n",
    "para hacer esto lo que haremos es dividir el costo del seguro en 3 categorias, bajo, medio y alto, para esto usaremos los cuartiles de los datos, los datos que esten en el primer cuartil seran bajo (0), los que esten en el segundo cuartil seran medio (1) y los que esten en el tercer cuartil seran alto (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90d5b46e4af6f854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:49.975089400Z",
     "start_time": "2023-09-10T20:24:49.966081300Z"
    }
   },
   "outputs": [],
   "source": [
    "Q1 = df['charges'].quantile(0.25)\n",
    "Q3 = df['charges'].quantile(0.75)\n",
    "\n",
    "df['category'] = 1\n",
    "df.loc[df['charges'] < Q1, 'category'] = 0\n",
    "df.loc[df['charges'] > Q3, 'category'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a052c8654e912",
   "metadata": {},
   "source": [
    "hacemos los mismos procesos que antes, solo que ahora la variable de salida es la categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "788e764101c03808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:50.305084800Z",
     "start_time": "2023-09-10T20:24:50.293073100Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['charges', 'category'])\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "497dda0c7b04f852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:50.488493300Z",
     "start_time": "2023-09-10T20:24:50.457244400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51ec3c43c45bf7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:50.660533100Z",
     "start_time": "2023-09-10T20:24:50.629648100Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fff0f606660a6723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:50.902685500Z",
     "start_time": "2023-09-10T20:24:50.886246800Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).view(-1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f507db6170746",
   "metadata": {},
   "source": [
    "Este nuevo modelo es de clasificacion que a diferencia del pasado que era de regresion su proposito es categorizar los datos de entrada en una de las 3 categorias que definimos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4be8e97644bc46c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:51.257948800Z",
     "start_time": "2023-09-10T20:24:51.246245400Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "model = ClassificationNN(X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4756b4bb8614c6d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:51.774532700Z",
     "start_time": "2023-09-10T20:24:51.625397800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.9585\n",
      "Epoch [20/100], Loss: 0.7667\n",
      "Epoch [30/100], Loss: 0.6707\n",
      "Epoch [40/100], Loss: 0.6552\n",
      "Epoch [50/100], Loss: 0.6492\n",
      "Epoch [60/100], Loss: 0.6466\n",
      "Epoch [70/100], Loss: 0.6451\n",
      "Epoch [80/100], Loss: 0.6441\n",
      "Epoch [90/100], Loss: 0.6434\n",
      "Epoch [100/100], Loss: 0.6429\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "930155e7cdb518c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:51.985725100Z",
     "start_time": "2023-09-10T20:24:51.965706300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.30%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80f22074a48ce1",
   "metadata": {},
   "source": [
    "Aqui podemos ver los resultados de la clasificacion de los seguros, en la que en un 90.3% de los casos el modelo clasifico correctamente el seguro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89703120d45827",
   "metadata": {},
   "source": [
    "En esta parte podemos ver las probabilidades que que las primeras 3 pruebas esten en cada una de las categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a264344253f4ae43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:52.807567Z",
     "start_time": "2023-09-10T20:24:52.785547200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1184e-12, 1.0000e+00, 1.8245e-06],\n",
       "        [1.0079e-01, 8.9821e-01, 1.0006e-03],\n",
       "        [6.4255e-17, 4.3202e-03, 9.9568e-01]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(X_test_tensor[:3], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661ef4ae15de493",
   "metadata": {},
   "source": [
    "Aqui podemos ver para las primeras 3 pruebas a que categoria se estan clasificando y cual es la probabilidad de que esten en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab9f1126356ceee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:53.527249400Z",
     "start_time": "2023-09-10T20:24:53.510233900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.0000, 0.8982, 0.9957], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([1, 1, 2]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(torch.tensor(X_test_tensor[:3], dtype=torch.float32)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e690c850abb2f4",
   "metadata": {},
   "source": [
    "Aqui podemos ver las categorias reales de las primeras 3 pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1a1c51f91fc3d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T20:24:54.785911400Z",
     "start_time": "2023-09-10T20:24:54.769057600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230aa0a772c37ea",
   "metadata": {},
   "source": [
    "En esta ultima prueba podemos cer que el modelo tiene una precision buena ahora que solo estamos clasificando si el seguro estara en una de 3 categorias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
